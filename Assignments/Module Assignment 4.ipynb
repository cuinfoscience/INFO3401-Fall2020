{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFO 3401 – Module Assignment 4\n",
    "\n",
    "[Brian C. Keegan, Ph.D.](http://brianckeegan.com/)  \n",
    "[Assistant Professor, Department of Information Science](https://www.colorado.edu/cmci/people/information-science/brian-c-keegan)  \n",
    "University of Colorado Boulder  \n",
    "\n",
    "Copyright and distributed under an [MIT License](https://opensource.org/licenses/MIT).\n",
    "\n",
    "## Learning Objectives\n",
    "This is the sole component for Module Assignment 4: there are no sub-assignments. This assignment is due Wednesday, October 28 by 11:59pm on Canvas. Please submit as an HTML file: File > Download as > HTML (.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our usual libraries for working with data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.options.display.max_columns = 100\n",
    "# pd.options.display.max_rows = 100\n",
    "\n",
    "# Our usual libraries for visualizing data\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import seaborn as sb\n",
    "\n",
    "# Spatial libaries\n",
    "import geopandas as gpd\n",
    "import geoplot, contextily"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data\n",
    "\n",
    "### Sales data\n",
    "Read in the \"colorado_monthly_cannabis_sales.csv\" file as `sales_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the number of rows and show the tail of `sales_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crime data\n",
    "\n",
    "Read in the \"co_county_crime.csv\" file as `crime_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the number of rows and show the tail of `crime_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### County shapefile\n",
    "\n",
    "Read in the \"co_counties\" shapefiles as `co_counties_gdf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the CRS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the number of rows and show the tail of `co_counties_gdf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "\n",
    "### Sales data\n",
    "In `sales_df`, cast the values in the \"Month\" column from strings to `pd.Timestamp` or `pd.Period` objects using an appropriate pandas function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NaNs are present in the \"Sales\" column if there are 3 or fewer dispensaries in a county in a given month to protect their confidentiality: \n",
    "\n",
    "> \"Per §39-21-113(4), C.R.S., data derived from taxpayer returns is aggregated in order to protect the confidentiality of individual taxpayers. It is the Department’s practice to release aggregated data only when there are at least three taxpayers in a given category and none of them represents more than 80% of the total.\n",
    "\n",
    "This is a good case for keeping rather than dropping NaNs: because a county doesn't report sales doesn't mean that it's not a legal county with dispensaries and sales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crime data\n",
    "\n",
    "In `crime_df`, cast the values in the \"Month\" column from strings to `pd.Timestamp` or `pd.Period` objects using an appropriate pandas function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counties data\n",
    "\n",
    "Convert the \"county\" column in `co_counties_gdf` to title-case ([hint](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.title.html)) and show the head after the change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory analysis\n",
    "\n",
    "### Sales data\n",
    "How many times does each county appear in `sales_df`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a histogram of the \"Sales\" values in `sales_df`. This might be highly-skewed, so experiment with using log-scaled bins and x-axis: try passing `np.logspace(3,8,25)` to the \"bins\" parameter and set the xscale to \"log\" ([hint](https://matplotlib.org/3.2.1/api/_as_gen/matplotlib.axes.Axes.set_xscale.html)). Make sure to label your axes. Real extra credit if you can format the x-axis to have more interpretable ticks too ([hint](https://matplotlib.org/3.3.1/gallery/ticks_and_spines/tick-formatters.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpret the histogram. What is the most common monthly sales value?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape the data with \"Time\" in the index and \"Medical\" and \"Recreational\" as columns and the total number of sales as values. Save the resulting reshape as `monthly_sales_pivot`. You can do this with a pivot table or a groupby-aggregation. Show the tail of this reshaped DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a lineplot of total medical and recreational cannabis sales by month using the DataFrame above. Label your axes and title. Real extra credit if you can format the y-axis to have more interpretable ticks too ([hint](https://matplotlib.org/3.1.0/gallery/ticks_and_spines/custom_ticker1.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick a county in Colorado and filter original sales DataFrame to only that county's values. Note that not all counties permit medical and/or recreational sales and thus may not be present in the data or they have changed their policies over time creating gaps. Make sure to pick a county with recreational sales. Reshape the data to include recreational and medical like we did above. Save the result as `county_monthly_sales_pivot`. Show the tail of this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the county-level data over time as a line plot like we did above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crime data\n",
    "\n",
    "How many times does each county appear in `crime_df`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape the data with \"Time\" in the index and \"DUI\" and \"Narcotics\" as columns and the total number of arrests as values. You can do this with a pivot table or a groupby-aggregation. Save the result as `monthly_crime_pivot` and show the tail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a lineplot of total DUI and Narcotics arrests by month using `monthly_crime_pivot`. Label your axes and title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick a county in Colorado and filter the crime DataFrame to only that county's values. Reshape the data to include DUIs and Narcotics like we did above. Save as `county_monthly_crime_pivot`. Show the tail of this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the county-level data over time as a line plot like we did above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine both state-level datasets\n",
    "\n",
    "Use `pd.merge` to combine the reshaped state-level DataFrames using an \"inner\" join called `combined_df` and inspect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new normalized DataFrame called `normalized_df` by [dividing](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.divide.html) by the January 2014 values in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the head of `normalized_df` to confirm the January 1, 2014 values are 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `normalized_df`, make a line plot with the normalized DUI and Recreational values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this a helpful visualization? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the [correlation coefficients](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.corr.html) between the columns in `normalized_df`. (The values are symmetrical around the diagonal.) Pick two different values and interpret them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `normalized_df`, make a scatter plot with \"Recreational\" on the x-axis and \"DUI\" on the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpret the plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `normalized_df`, make a scatter plot data with \"Recreational\" on the x-axis and \"Narcotics\" on the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpet this plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial visualization\n",
    "\n",
    "### Sales data\n",
    "Merge the county GeoDataFrame (left) with the original sales data (right) with a left join on the county names to a GeoDataFrame called `sales_gdf`. Check to make sure the merged object is a GeoDataFrame, print the shape, and inspect the head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the data to \"Recreational\" sales in December 2014. Visualize the \"Sales\" as a choropleth. Bonus points for using a basemap. Extra bonus points for using a [lognorm colormap](https://matplotlib.org/3.1.0/gallery/userdemo/colormap_normalizations_lognorm.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the data to \"Recreational\" sales in December 2019. Visualize the \"Sales\" as a choropleth. Bonus points for using a basemap. Extra bonus points for using a [lognorm colormap](https://matplotlib.org/3.1.0/gallery/userdemo/colormap_normalizations_lognorm.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpet some changes you observe between the two maps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crime data\n",
    "\n",
    "Merge `co_counties_gdf` (left) with `crime_df` (right) into a GeoDataFrame called `crime_gdf`. Check to make sure the merged object is a GeoDataFrame, print the shape, and inspect the head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the data to \"DUI\" sales in December 2014. Visualize the \"Arrests\" as a choropleth. Bonus points for using a basemap. Extra bonus points for using a [lognorm](https://matplotlib.org/3.1.0/gallery/userdemo/colormap_normalizations_lognorm.html) or [symlognorm](https://matplotlib.org/3.3.1/gallery/userdemo/colormap_normalizations_symlognorm.html#sphx-glr-gallery-userdemo-colormap-normalizations-symlognorm-py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the data to \"DUI\" sales in December 2019. Visualize the \"Arrests\" as a choropleth. Bonus points for using a basemap. Extra bonus points for using a [lognorm](https://matplotlib.org/3.1.0/gallery/userdemo/colormap_normalizations_lognorm.html) or [symlognorm](https://matplotlib.org/3.3.1/gallery/userdemo/colormap_normalizations_symlognorm.html#sphx-glr-gallery-userdemo-colormap-normalizations-symlognorm-py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpet some changes you observe between the two maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changes in crime for legalizing vs. non-legalizing counties\n",
    "\n",
    "From the December 2019 recreational GeoDataFrame you made, identify the unique counties that had reported recreational cannabis sales. Save this as `rec_counties_l`. Note that this is an inaccurate enumeration of counties with legalized cannabis salies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the Colorado counties GeoDataFrame, identify all the unique counties in Colorado. Save this as `all_counties_l`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `rec_counties_l` and `co_counties_l`, do a set operation to identify all the counties with no reported recreational cannabis sales. Save this as `nonrec_counties_l`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below will compute the change in crime for 2019 versus 2013 for each county."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_pivot_df = pd.pivot_table(crime_df,index=['Time','County'],columns='Type',values='Arrests')\n",
    "crime_2019 = crime_pivot_df.loc['2019-01-01':'2019-12-01'].sum(level=1)\n",
    "crime_2013 = crime_pivot_df.loc['2013-01-01':'2013-12-01'].sum(level=1)\n",
    "crime_change_df = crime_2019 - crime_2013\n",
    "crime_change_df.reset_index(inplace=True)\n",
    "crime_change_df.columns.name = None\n",
    "crime_change_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a new column in `crime_change_df` called \"Rec\" that is a Boolean value of whether that county had any reported recreational sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a seaborn `barplot` with \"Rec\" on the x-axis and \"DUI\" on the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a seaborn `barplot` with \"Rec\" on the x-axis and \"Narcotics\" on the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a statistical test for whether the observed differences are statistically significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "rec_dui_changes = crime_change_df.loc[crime_change_df['County'].isin(rec_counties_l),'DUI']\n",
    "nonrec_dui_changes = crime_change_df.loc[crime_change_df['County'].isin(nonrec_counties_l),'DUI']\n",
    "\n",
    "stats.ttest_ind(rec_dui_changes,nonrec_dui_changes,equal_var=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_narcotics_changes = crime_change_df.loc[crime_change_df['County'].isin(rec_counties_l),'Narcotics']\n",
    "nonrec_narcotics_changes = crime_change_df.loc[crime_change_df['County'].isin(nonrec_counties_l),'Narcotics']\n",
    "\n",
    "stats.ttest_ind(rec_narcotics_changes,nonrec_narcotics_changes,equal_var=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discuss\n",
    "Interpet the observed changes in crime statistics between 2013 and 2019 for legalizing and non-legalizing counties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix\n",
    "\n",
    "Here's the steps I took to collect and clean up some of the data used for this module. **There's nothing you need to run in here to complete any part of this assignment**, I just share it in the interests of transparency and supporting motivated learners. \n",
    "\n",
    "Libraries only needed for the appendix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests, os, re, time\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import quote, unquote\n",
    "from datetime import datetime\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sales reports\n",
    "The Colorado Department of Revenue's [Manrijuana Sales Reports](https://revenue.colorado.gov/data-and-reports/marijuana-data/marijuana-sales-reports) stores Excel files on a Google Drive.\n",
    "\n",
    "First, get all the links to each month's report by retrieving and parsing the markup from the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the raw HTML of the page\n",
    "raw = requests.get('https://revenue.colorado.gov/data-and-reports/marijuana-data/marijuana-sales-reports')\n",
    "\n",
    "# Turn into Soup\n",
    "soup = BeautifulSoup(raw.text)\n",
    "\n",
    "# Find the elements corresponding to the containers with the yearly data\n",
    "containers = soup.find_all('dl',{'class':'ckeditor-accordion'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, download all the Excel files. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "excel_files = {}\n",
    "\n",
    "# Each container contains the links to the Excel and PDF files for each month\n",
    "for year in containers:\n",
    "    \n",
    "    # Get only the Excel URLs\n",
    "    _google_sheets_urls = [a['href'] for a in year.find_all('a') if a.text == 'Excel']\n",
    "    \n",
    "    # Loop through these URLs\n",
    "    for url in _google_sheets_urls:\n",
    "        \n",
    "        # Download each file. https://stackoverflow.com/a/56611995/1574687\n",
    "        # First extract the ID for each file\n",
    "        _id = re.findall('\\/file\\/d\\/([\\w-]+)\\/view\\?',url)[0]\n",
    "        \n",
    "        # Then pass it back to this reformatted export URL to download\n",
    "        _excel_df = pd.read_excel('https://drive.google.com/uc?export=download&id=' + _id)\n",
    "        \n",
    "        # Get the date from inside the data\n",
    "        _date = _excel_df.iloc[1,0].replace('Sales from ','')\n",
    "        _formatted_date = str(pd.Period(_date))\n",
    "        \n",
    "        # Save\n",
    "        excel_files[_formatted_date] = _excel_df\n",
    "        \n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm we got them all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(excel_files.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to parse the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_excel(_df):\n",
    "    \n",
    "    # Drop first 5 rows\n",
    "    _df = _df.drop(index=range(5)).reset_index(drop=True)\n",
    "    \n",
    "    # Drop empty column\n",
    "    _df = _df.dropna(how='all',axis=1)\n",
    "    \n",
    "    # Rename columns\n",
    "    _df.columns = ['Med County','Med Sales','Rec County','Rec Sales']\n",
    "    \n",
    "    # Find row for last medical and recreational sales\n",
    "    last_med = _df[_df['Med County'].str.contains('Sum of NR Counties').fillna(False)].first_valid_index() - 1\n",
    "    last_rec = _df[_df['Rec County'].str.contains('Sum of NR Counties').fillna(False)].first_valid_index() - 1\n",
    "\n",
    "    # Slice to only those values\n",
    "    med_sales = _df.loc[:last_med,['Med County','Med Sales']]\n",
    "    rec_sales = _df.loc[:last_rec,['Rec County','Rec Sales']]\n",
    "    \n",
    "    # Rename columns\n",
    "    med_sales.columns = ['County','Sales']\n",
    "    rec_sales.columns = ['County','Sales']\n",
    "\n",
    "    # Add type\n",
    "    med_sales['Type'] = 'Medical'\n",
    "    rec_sales['Type'] = 'Recreational'\n",
    "    \n",
    "    # Concatenate\n",
    "    combined_df = pd.concat([med_sales,rec_sales],ignore_index=True)\n",
    "    combined_df = combined_df.replace({'Sales':{'NR':np.nan}})\n",
    "\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through files, parse out relevant data, and concatenate results together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dict = {}\n",
    "\n",
    "# Apply the function to each month's spreadsheet\n",
    "for _month, _df in excel_files.items():\n",
    "    try:\n",
    "        cleaned_dict[_month] = clean_excel(_df)\n",
    "    except:\n",
    "        print(_month)\n",
    "        pass\n",
    "\n",
    "# Combine all the months of data together\n",
    "combined_df = pd.concat(cleaned_dict.values(),keys=cleaned_dict.keys())\n",
    "\n",
    "# Cleanup\n",
    "combined_df = combined_df.reset_index(0).reset_index(drop=True)\n",
    "combined_df = combined_df.rename(columns={'level_0':'Time'})\n",
    "\n",
    "combined_df = combined_df.sort_values(['Time','County','Type'])\n",
    "\n",
    "# Write to disk\n",
    "combined_df.to_csv('colorado_monthly_cannabis_sales.csv',index=False)\n",
    "\n",
    "print(combined_df.shape)\n",
    "combined_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old method using files I manually downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dir = 'E:/Dropbox/Courses/2020 Fall - INFO 3401/Code and data/cannabis_sales/'\n",
    "files = [f for f in os.listdir(_dir) if '.xlsx' in f]\n",
    "\n",
    "data_dict = {}\n",
    "# filename_prefixes = [i.strftime('%m%y') for i in pd.period_range('2014-01','2020-10',freq='1M')]\n",
    "\n",
    "_dir = 'E:/Dropbox/Courses/2020 Fall - INFO 3401/Code and data/cannabis_sales/'\n",
    "files = [f for f in os.listdir(_dir) if '.xlsx' in f]\n",
    "\n",
    "for month,df in files:\n",
    "    try:\n",
    "        period = pd.Period(datetime.strptime(f.split('_')[0],'%m%y'),freq='1M')\n",
    "        data_dict[period] = pd.read_excel(_dir+f) #,skiprows=5)\n",
    "    except:\n",
    "        print(f)\n",
    "        pass\n",
    "\n",
    "print(len(data_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crime\n",
    "\n",
    "https://coloradocrimestats.state.co.us/public/View/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_dui_1719 = pd.read_csv('DUI Arrests 2017-2019.csv',skiprows=3).dropna(how='all',axis=1)\n",
    "co_dui_1316 = pd.read_csv('DUI Arrests 2013-2016.csv',skiprows=3).dropna(how='all',axis=1)\n",
    "\n",
    "co_dui_df = pd.concat([co_dui_1316,co_dui_1719],ignore_index=True)\n",
    "co_dui_df['Incident Date'] = pd.to_datetime(co_dui_df['Incident Date'])\n",
    "co_dui_df = co_dui_df.drop(columns=['Arrest Offense for A and B Arrests'])\n",
    "\n",
    "co_dui_df = pd.pivot_table(data = co_dui_df,\n",
    "                           columns = 'Jurisdiction by Geography',\n",
    "                           index = 'Incident Date',\n",
    "                           values = 'Number of Arrestees'\n",
    "                          )\n",
    "\n",
    "co_dui_df = co_dui_df.fillna(0)\n",
    "\n",
    "co_dui_df = co_dui_df.groupby(pd.Grouper(freq='1M')).sum().stack().reset_index()\n",
    "co_dui_df.columns = ['Time','County','Arrests']\n",
    "co_dui_df['Time'] = co_dui_df['Time'].dt.to_period(freq='1M')\n",
    "\n",
    "_rename = {c:c.replace(' County','') for c in co_dui_df['County'].unique().tolist() if 'County' in c}\n",
    "co_dui_df = co_dui_df.replace({'County':_rename})\n",
    "\n",
    "# co_dui_df.to_csv('co_county_dui.csv')\n",
    "\n",
    "# co_dui_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_narcotics_1719 = pd.read_csv('Narcotics Arrests 2017-2019.csv',skiprows=3).dropna(how='all',axis=1)\n",
    "co_narcotics_1316 = pd.read_csv('Narcotics Arrests 2013-2016.csv',skiprows=3).dropna(how='all',axis=1)\n",
    "\n",
    "co_narcotics_df = pd.concat([co_narcotics_1316,co_narcotics_1719],ignore_index=True)\n",
    "co_narcotics_df['Incident Date'] = pd.to_datetime(co_narcotics_df['Incident Date'])\n",
    "co_narcotics_df = co_narcotics_df.drop(columns=['Arrest Offense for A and B Arrests'])\n",
    "\n",
    "co_narcotics_df = pd.pivot_table(data = co_narcotics_df,\n",
    "                           columns = 'Jurisdiction by Geography',\n",
    "                           index = 'Incident Date',\n",
    "                           values = 'Number of Arrestees'\n",
    "                          )\n",
    "\n",
    "co_narcotics_df = co_narcotics_df.fillna(0)\n",
    "\n",
    "co_narcotics_df = co_narcotics_df.groupby(pd.Grouper(freq='1M')).sum().stack().reset_index()\n",
    "co_narcotics_df.columns = ['Time','County','Arrests']\n",
    "co_narcotics_df['Time'] = co_narcotics_df['Time'].dt.to_period(freq='1M')\n",
    "\n",
    "_rename = {c:c.replace(' County','') for c in co_narcotics_df['County'].unique().tolist() if 'County' in c}\n",
    "co_narcotics_df = co_narcotics_df.replace({'County':_rename})\n",
    "\n",
    "# co_narcotics_df.to_csv('co_county_narcotics.csv')\n",
    "\n",
    "# co_narcotics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_county_crime_df = pd.concat([co_dui_df,co_narcotics_df],\n",
    "                               keys=['DUI','Narcotics'],\n",
    "                               names=['Type']\n",
    "                              ).reset_index(0)\n",
    "co_county_crime_df = co_county_crime_df[['Time','County','Type','Arrests']]\n",
    "\n",
    "co_county_crime_df = co_county_crime_df.sort_values(['Time','County','Type']).reset_index(drop=True)\n",
    "\n",
    "co_county_crime_df.to_csv('co_county_crime.csv',index=False)\n",
    "\n",
    "co_county_crime_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_county_crime_df = pd.merge(left = co_dui_df,\n",
    "                              right = co_narcotics_df,\n",
    "                              how = 'outer',\n",
    "                              left_on = ['Time','County'],\n",
    "                              right_on = ['Time','County']\n",
    "                             )\n",
    "\n",
    "co_county_crime_df.to_csv('co_county_crime.csv',index=False)\n",
    "\n",
    "co_county_crime_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
